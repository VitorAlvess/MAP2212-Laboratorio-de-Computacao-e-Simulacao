\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage[margin=2cm]{geometry}

\title{Relatório - Exercício Programa 2 (EP2)}
\author{José Victor Santos Alves \\ Nº USP: 14713085}
\date{abril de 2025}

\begin{document}

\maketitle
\thispagestyle{empty}

\begin{abstract}
Este relatório apresenta a solução para o segundo Exercício Programa (EP2) da disciplina MAP2212/2025 (Laboratório de Computação e Simulação) do Bacharelado em Matemática Aplicada e Computacional (BMAC) do IME-USP. O objetivo é implementar quatro variantes do método de Monte Carlo para calcular a integral da função \( f(x) = e^{-ax}\cos(bx) \) no intervalo \([0,1]\), onde \( a = 0.RG \) e \( b = 0.CPF \), sendo \( RG \) e \( CPF \) dígitos do número de identificação do autor.
\end{abstract}

\section{Introdução}
\label{sec:intro}

Este trabalho visa explorar métodos estocásticos de integração numérica, com ênfase nas quatro variantes de Monte Carlo:

\begin{itemize}
    \item Crude
    \item \textit{Hit or Miss}
    \item Amostragem por importância (\textit{Importance Sampling})
    \item Variáveis de controle (\textit{Control Variates})
\end{itemize}

A função a ser integrada é:

\begin{equation}
    f(x) = e^{-ax}\cos(bx), \quad x \in [0,1]
    \label{eq:funcao}
\end{equation}

onde \( a = 0.\overline{RG} \) e \( b = 0.\overline{CPF} \) ficando \(a = 0.5296090 \) e \(b = 0.529809068\)

\section{Metodologia}
\label{sec:metodo}

\subsection{Implementação}
Foram implementados em Python os seguintes métodos:

\subsubsection{Método Crude (\text{no python def crude()) }}
\begin{equation}
    I_{\text{crude}} = \frac{1}{N}\sum_{i=1}^N f(x_i), \quad x_i \sim \mathcal{U}(0,1)
\end{equation}

\subsubsection{Método Hit or Miss (\text{no python def hit\_or\_miss() })}
\begin{equation}
    I_{\text{HM}} = \frac{\text{Acertos}}{N}, \quad \text{onde } \text{Acertos} = \sum_{i=1}^N \mathbb{I}(y_i \leq f(x_i))
\end{equation}

\subsubsection{Importance Sampling (\text{no python def importance\_sampling()) }} 
Utilizando \( g(x) = ae^{-ax} \) como distribuição de importância:

\begin{equation}
    I_{\text{IS}} = \frac{1}{N}\sum_{i=1}^N \frac{f(x_i)}{g(x_i)}, \quad x_i \sim g(x)
\end{equation}

\subsubsection{Control Variates (\text{no python def control\_variates()) }}
Com \( h(x) = x \) como variável de controle:

\begin{equation}
    I_{\text{CV}} = \frac{1}{N}\sum_{i=1}^N \left[f(x_i) - \beta h(x_i)\right] + \beta C
\end{equation}
onde \( C = \int_0^1 h(x)dx = 0.5 \).

\section{Cálculo do Erro Relativo}
\label{sec:erro}

Para avaliar a precisão da estimativa obtida pelos métodos de Monte Carlo, utilizou-se o \textbf{erro relativo}, definido como:

\begin{equation}
\text{Erro Relativo} = \frac{|\hat{\gamma} - \gamma|}{\gamma} < 0,0005
\label{eq:erro_rel}
\end{equation}

onde:
\begin{itemize}
    \item $\hat{\gamma}$ é a estimativa da integral
    \item $\gamma$ é o valor verdadeiro (desconhecido pelo enunciado do EP) da integral.
\end{itemize}

\subsection{Calculo de n}
\label{sec:teoria-n}

Para garantir que o erro relativo da estimativa seja menor que  $\epsilon = 0.0005$, o número de amostras $n$ é determinado pela relação fundamental:

\begin{equation}
n > \left( \frac{\sigma}{\epsilon \cdot \hat{\gamma}} \right)^2,
\label{eq:n-minimo}
\end{equation}

onde:
\begin{itemize}
    \item $\sigma$ é o desvio padrão das estimativas,
    \item $\hat{\gamma}$ é a média amostral da integral,
    \item $\epsilon$ é o erro relativo.
\end{itemize}


A Equação~\ref{eq:n-minimo} deriva do \textbf{Teorema Central do Limite} , que estabelece que a distribuição das médias amostrais $\hat{\gamma}$ é aproximadamente normal para $n$ grande:

\begin{equation}
\hat{\gamma} \sim \mathcal{N}\left(\gamma, \frac{\sigma^2}{n}\right),
\end{equation}

onde $\gamma$ é o valor verdadeiro da integral. O erro absoluto é então:

\begin{equation}
|\hat{\gamma} - \gamma| \approx \frac{\sigma}{\sqrt{n}}.
\end{equation}

\subsection{Cálculo do Desvio Padrão por Método}

\subsubsection{Método Crude}
Para $f(x)$ com $x_i \sim \mathcal{U}(0,1)$:

\begin{equation}
\sigma^2 = \text{Var}(f(x)) = \mathbb{E}[f(x)^2] - \mathbb{E}[f(x)]^2
\end{equation}

\subsubsection{Método Hit-or-Miss}
Para variáveis binárias $I_i = \mathbb{I}(y_i \leq f(x_i))$:

\begin{equation}
\sigma^2 = \hat{\gamma}(1 - \hat{\gamma}), \quad \hat{\gamma} = \frac{1}{n}\sum_{i=1}^n I_i
\end{equation}

\subsubsection{Amostragem por Importância}
Com amostras $x_i \sim g(x)$:

\begin{equation}
\sigma^2 = \text{Var}\left(\frac{f(x)}{g(x)}\right)
\end{equation}

\subsubsection{Variáveis de Controle}
Com função de controle $h(x)$:

\begin{equation}
\sigma^2 = \text{Var}\left(f(x) - \beta h(x)\right), \quad \beta = \frac{\text{Cov}(f,h)}{\text{Var}(h)}
\end{equation}

\section{Resultados}
\label{sec:resultados}

Os métodos foram testados com \( N = 10^3 \) amostras obtendo os seguintes resultados:

\begin{table}[h]
\centering
\caption{Comparação dos métodos para \(N = 10^3\) amostras}
\begin{tabular}{|l|c|c|c|}
\hline
Método & Estimativa & Variância  & n\\ \hline
Crude &  0.7457778567215412 & 0.02035148643428586 & 146365\\ \hline
Hit or Miss & 0.74595 & 0.1895085975 & 1365158 \\ \hline
Importance Sampling & 0.7270688621887386 & 0.7352583205886564 & 5563510\\ \hline
Control Variates & 0.0.7451659518118909 & 0.42978898852212033 & 3096059\\ \hline
\end{tabular}
\end{table}

Os métodos foram testados com \( N = 10^5 \) amostras obtendo os seguintes resultados:

\begin{table}[h]
\centering
\caption{Comparação dos métodos para \(N = 10^5\) amostras}
\begin{tabular}{|l|c|c|c|}
\hline
Método & Estimativa & Variância  & n\\ \hline
Crude &   0.7454976571593395 & 0.020327190667182693 & 146300\\ \hline
Hit or Miss & 0.74864 & 0.18817815040000002 & 1355624 \\ \hline
Importance Sampling &  0.7254483754336972 & 0.7382258493272087 & 5610948\\ \hline
Control Variates & 0.7451521970699198 & 0.4297644195692293 & 3095997\\ \hline
\end{tabular}
\end{table}

\section{Conclusão}
\label{sec:conclusao}

A partir dos dados obtidos, podemos observar que o método Crude apresentou a menor variância, indicando maior precisão com menos amostras. Os métodos Hit or Miss e Control Variates precisaram de 10 vezes mais amostras que o Crude, e o método Importance Sampling foi o menos eficiente. Um dos principais fatores que influenciou esse resultado foi a escolha da distribuição de importância \( g(x) = ae^{-ax} \) (que se provou uma má escolha), pois o valor estimado da integral utilizando esse método ficou relativamente distante dos outros - enquanto os demais métodos convergiram para valores em torno de 0.74, este ficou em 0.72.






\end{document}